from typing import List
from rouge_score import rouge_scorer
from gspread_dataframe import get_as_dataframe, set_with_dataframe
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials

scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]

import streamlit as st
credentials = ServiceAccountCredentials.from_json_keyfile_dict(
    st.secrets["google_service_account"], scope
)
client = gspread.authorize(credentials)

spreadsheet = client.open("Financial Title Generator")
worksheet = spreadsheet.worksheet("Titles")


def get_llm_response(prompt: str, model: str, api_key: str) -> str:
    """
    Get a response from the LLM (Language Model) based on the provided prompt.
    
    Args:
        prompt (str): The prompt to send to the LLM.
        model (str): The model to use for generating the response.
        
    Returns:
        str: The response from the LLM.
    """
    print(f"Getting LLM response for prompt: {prompt} with api_key: {api_key}")
    # TODO: Placeholder for actual LLM response logic
    return "LLM Response"

    # client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    # try:
    #     response = client.chat.completions.create(
    #         model=model
    #         messages=[{"role": "user", "content": prompt}]
    #     )
    #     return response.choices[0].message.content
    # except Exception as e:
    #     return f"Error calling LLM: {e}"


def get_content_from_url(url: str) -> str:
    """
    Placeholder function to fetch content from a given URL.
    In a real application, this would involve web scraping or an API call.
    
    Args:
        url (str): The URL to fetch content from.
        
    Returns:
        str: The extracted content from the URL.
    """
    print(f"Fetching content from URL: {url}")
    # TODO: Implement actual URL content extraction (e.g., using requests and BeautifulSoup)
    return f"This is placeholder content extracted from the URL: {url}. It contains information relevant to financial titles."


def make_prompt_for_llm(text_content: str, is_url_content: bool = False) -> str:
    """
    Create a prompt for the LLM based on the provided summary or URL content.
    
    Args:
        text_content (str): The summary or content extracted from URL to include in the prompt.
        is_url_content (bool): True if text_content is from a URL, False if it's a summary.
        
    Returns:
        str: The generated prompt.
    """
    print(f"Creating prompt with {'URL content' if is_url_content else 'summary'}")
    if is_url_content:
        prompt = "" #TODO: Placeholder for actual URL content prompt logic
    else:
        prompt = "" #TODO: Placeholder for actual URL content prompt logic
    return prompt


def clean_response(response: str) -> List[str]:
    """
    Clean the response from the LLM to extract the relevant information.
    
    Args:
        response (str): The response from the LLM.
        
    Returns:
        List[str]: A list of cleaned titles.
    """
    print(f"Cleaning response")
    # TODO: Placeholder for actual response cleaning logic
    generate_titles = ["Generated Title 1", "Generated Title 2", "Generated Title 3", "Generated Title 4", "Generated Title 5"]
    return generate_titles


def generate_titles(summary: str, model: str, api_key:str, is_url_content: bool = False) -> List[str]:
    """
    Generate titles based on the provided summary/URL content using the specified model.
    
    Args:
        summary (str): The summary text or URL content to generate titles for.
        model (str): The model to use for title generation.
        is_url_content (bool): True if summary is from a URL, False if it's a direct summary.
        
    Returns:
        List[str]: A list of generated titles.
    """
    print(f"Generating titles for content: {summary} using model: {model}")
    prompt = make_prompt_for_llm(text_content=summary, is_url_content=is_url_content)
    response = get_llm_response(prompt=prompt, model=model, api_key=api_key)
    generated_titles = clean_response(response)
    return generated_titles


def calculate_rouge_scores(title: str, generated_title: str) -> float:
    """
    Calculate the ROUGE score between the original title and the generated title.
    
    Args:
        title (str): The title given by the user.
        generated_title (str): The title generated by the model.
        
    Returns:
        float: The ROUGE-1 F-measure score.
    """
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)
    scores = scorer.score(title, generated_title)
    score = round(scores['rouge1'].fmeasure, 3)
    return (score)


def generate_titles_with_rogue_scores(summary: str, model: str, user_title: str, api_key:str) -> List[str]:
    """
    Generate titles based on the provided summary using the specified model, and calculate ROUGE scores.
    
    Args:
        summary (str): The summary text to generate titles for.
        model (str): The model to use for title generation.
        user_title (str): The user-provided title for ROUGE score calculation.
        
    Returns:
        List[str]: A list of generated titles with ROUGE scores appended.
    """
    generated_titles= generate_titles(summary=summary, model=model, api_key=api_key, is_url_content=False)
    generated_titles_with_rouge_scores = []
    for generated_title in generated_titles:
        rouge_score = calculate_rouge_scores(title=user_title, generated_title=generated_title)
        generated_titles_with_rouge_scores.append(f"{generated_title} \t- ROUGE Score: {rouge_score}")
    print(f"Generated titles with ROUGE scores")
    return generated_titles_with_rouge_scores


def save_to_database(data: List) -> bool:
    """
    Save the generated titles and their ROUGE scores to a database.
    
    Args:
        data (List[Any]): The data to save to the database.
                          Expected format: [summary/URL, user_title, model, selected_title, rouge_score (optional)]
        
    Returns:
        bool: True if saving was successful, False otherwise.
    """
    print(f"Saving data to database: {data}")
    try:
        df = read_from_database()
        if not df.empty:
            df["ID"] = pd.to_numeric(df["ID"], errors="coerce")
            new_id = df["ID"].max() + 1
        else:
            new_id = 1
            
        selected_title = data[3] if len(data) > 3 else ""
        if " \t- ROUGE Score: " in selected_title:
            title, score = selected_title.split(" \t- ROUGE Score: ", 1)
            data[3] = title.strip()
            data.append(score.strip())
        else:
            data.append("")            
            
        data.insert(0, new_id)
        worksheet.append_row(data)
        return True
    except Exception as e:
        print(f"Error saving data to database: {e}")
        return False


def read_from_database() -> pd.DataFrame:
    """
    Read data from the database.
    
    Returns:
        pd.DataFrame: The data read from the database.
    """
    print(f"Reading data from spreadsheets")
    df = get_as_dataframe(worksheet, evaluate_formulas=True).dropna(how="all")
    return df